{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn\n",
    "import os\n",
    "import string\n",
    "from PIL import Image\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a mapping from the image files to the character they represents\n",
    "character_list = list(string.digits + string.ascii_uppercase + string.ascii_lowercase)\n",
    "nums = range(1,len(a)+1)\n",
    "file_to_character = dict(zip(nums, character_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take the median size of the images as the standard_size for \n",
    "# normalization of the images\n",
    "path = '/home/reza/MachineLearning/Hand-Writing-Recognition/data/English/img/'\n",
    "img_sizes = []\n",
    "for folder in os.listdir(path):\n",
    "    for img_file in os.listdir(path+'/'+folder+'/'):\n",
    "        img = Image.open(path+'/'+folder+'/'+img_file)\n",
    "        img_sizes.append(img.size)\n",
    "\n",
    "# resize function only takes int values\n",
    "STANDARD_SIZE = map(int, median(img_sizes, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[158 158 157 ..., 153 153 152]\n",
      " [159 159 157 ..., 154 154 154]\n",
      " [157 159 159 ..., 155 154 155]\n",
      " ..., \n",
      " [162 158 155 ..., 154 154 153]\n",
      " [152 154 155 ..., 154 154 152]\n",
      " [154 157 158 ..., 154 154 151]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([158, 158, 157, ..., 154, 154, 151], dtype=uint8)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an image class that allows us to represent the image in matrix or vector from\n",
    "class img():\n",
    "    def __init__(self, img_file=None, img_path=None):\n",
    "        if img_file is None or file_name is None:\n",
    "            raise Exception('Must give an image file as input along'\n",
    "                            'with its file name')\n",
    "        self.img_matrix = None\n",
    "        self.img_vector = None\n",
    "        self.img_label = None\n",
    "        self.img_file = img_file\n",
    "        self.img_path = img_path\n",
    "        \n",
    "    def img_to_matrix(self):\n",
    "        \"\"\"\n",
    "        Extract a matrix representation of the image\n",
    "        \"\"\"\n",
    "        # Resize the image to a standard size\n",
    "        img_resized = self.img_file.resize(STANDARD_SIZE)\n",
    "        self.img_matrix = array(img_resized)\n",
    "#         self.img_matrix = list(img_resized.getdata())\n",
    "#         if type(self.img_matrix[0]) is tuple:\n",
    "#             self.img_matrix = map(list, self.img_matrix)\n",
    "#             self.img_matrix = np.array(self.img_matrix)\n",
    "#         else:\n",
    "#         self.img_matrix = np.array(self.img_matrix)\n",
    "#         self.img_matrix.shape = (1, self.img_matrix.shape[0]) \n",
    "    def flatten_image(self):\n",
    "        \"\"\"\n",
    "        Flatten the matrix representation of the image. If the\n",
    "        matrix has shape (m, n) then the vector representation\n",
    "        has shape (1, m * n)\n",
    "        \"\"\"\n",
    "        if self.img_matrix is None:\n",
    "            self.img_to_matrix()\n",
    "        s = self.img_matrix.shape[0] * self.img_matrix.shape[1]\n",
    "        self.img_vector = self.img_matrix.reshape(1, s)[0]\n",
    "\n",
    "    def get_img_label(self):\n",
    "        \"\"\"\"\n",
    "        Sets the label for the image file, i.e, the English\n",
    "        character the image is showing\n",
    "        \"\"\"\n",
    "        file_name = self.img_path.split('/')[-1][3:6]\n",
    "        self.img_label = file_to_character[int(file_name)]\n",
    "        \n",
    "img1 = img(img_file=img_file, img_path='blahblah/im-001')\n",
    "img1.img_label\n",
    "img1.img_to_matrix()\n",
    "print img1.img_matrix\n",
    "img1.flatten_image()\n",
    "img1.img_vector\n",
    "# img1.get_img_label()\n",
    "# img1.img_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Gather features of the image for building the training data\n",
    "path = '/home/reza/MachineLearning/Hand-Writing-Recognition/data/English/img/'\n",
    "data = []\n",
    "labels = []\n",
    "for folder in os.listdir(path):\n",
    "    for img_file in os.listdir(path+'/'+folder+'/'):\n",
    "        img_file = Image.open(path+'/'+folder+'/'+img_file)\n",
    "        img_path = img_file.filename\n",
    "        img_file = img_file.convert('L')\n",
    "        \n",
    "        # Open in the image file\n",
    "        curr_img = img(img_file=img_file, img_path=img_path)\n",
    "        \n",
    "        # Take a vectore representation of the image\n",
    "        curr_img.flatten_image()\n",
    "        data.append(curr_img.img_vector)\n",
    "        \n",
    "        # add the label\n",
    "        curr_img.get_img_label()\n",
    "        labels.append(curr_img.img_label)\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Create the training data\n",
    "pca = RandomizedPCA(n_components=200)\n",
    "X = pca.fit_transform(data)\n",
    "df = DataFrame(X)\n",
    "response = 'label'\n",
    "df[response] = labels\n",
    "\n",
    "# Divide data to test and train\n",
    "mask = np.random.rand(len(df)) < 0.75\n",
    "train_dat = df[mask]\n",
    "test_dat = df[~mask]\n",
    "y_test = np.array(test_dat[response])\n",
    "test_dat.drop(response, axis=1, inplace=True)\n",
    "\n",
    "# Run random forest on the train model and pick the number\n",
    "# of trees used for the model\n",
    "rf = RandomForestClassifier(n_estimators=100, oob_score=True)\n",
    "rf.fit(train_dat.drop(response, axis=1), train_dat[response])\n",
    "prediction = rf.predict(test_dat)\n",
    "\n",
    "# # Check error percentage on the test set and tune parameters\n",
    "mean(prediction != y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['E'], dtype=object)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets test this on a sample image\n",
    "path = '/home/reza/Downloads/test.jpg'\n",
    "img_file = Image.open(path)\n",
    "img_path = img_file.filename\n",
    "img_file = img_file.convert('L')\n",
    "        \n",
    "# Open in the image file\n",
    "curr_img = img(img_file=img_file, img_path=img_path)\n",
    "        \n",
    "# Take a vectore representation of the image\n",
    "curr_img.flatten_image()\n",
    "test_point = pca.transform(curr_img.img_vector)\n",
    "\n",
    "# Predict the label for the test point\n",
    "rf.predict(test_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.34577558e+03,   6.84556293e+02,   5.59208035e+01,\n",
       "         -8.46845980e+02,  -4.41662885e+02,  -2.76884066e+01,\n",
       "          1.44019059e+02,   3.21069032e+02,   4.93002186e+02,\n",
       "         -1.74616988e+02,  -1.44020397e+02,  -2.81885666e+02,\n",
       "         -4.09568842e+02,   1.35128162e+02,  -2.57477347e+02,\n",
       "          4.05459057e+01,   3.06752019e+02,  -2.25583296e+02,\n",
       "         -3.40521745e+01,   5.80173919e+01,  -1.31436216e+02,\n",
       "          5.92273735e+00,  -1.88621552e+01,  -4.34929528e+02,\n",
       "          9.64304280e+01,   4.16957982e+01,   1.63363781e+02,\n",
       "         -7.13771988e+01,  -2.06998188e+02,   1.45761422e+02,\n",
       "          1.26428248e+02,   7.63334545e+01,  -1.76459278e+02,\n",
       "         -1.05714390e+02,   1.10165275e+02,  -1.46324568e+02,\n",
       "          9.25733320e+01,   8.84218509e+01,  -1.71506714e+02,\n",
       "          2.86410992e+01,   8.56800328e+01,  -7.13905291e+01,\n",
       "          3.15125133e+01,   8.33700841e+01,  -9.23399038e+01,\n",
       "         -5.19382454e+01,  -1.97859510e+02,   1.43309754e+02,\n",
       "         -8.63216662e+00,   1.04687497e+02,   1.19203160e+02,\n",
       "         -2.00435826e+02,  -7.05769532e+01,   7.83407878e+01,\n",
       "         -2.48818343e+02,  -5.75694302e+01,   5.38804017e+01,\n",
       "          4.09278181e+01,   1.64915448e+02,  -2.01190270e+02,\n",
       "         -8.61174815e+01,  -1.38308200e+02,  -1.66076720e+02,\n",
       "          1.34911219e+02,  -6.67517383e+01,  -1.36253965e+01,\n",
       "         -3.74357980e+01,  -4.83355957e+01,   7.77405702e+00,\n",
       "          8.36923010e+01,  -1.00304054e+02,   1.04906262e+02,\n",
       "         -5.95667547e+01,   6.04566832e+01,  -1.68784005e+02,\n",
       "         -1.31652367e+02,   1.13253013e+02,  -9.45363635e+01,\n",
       "         -1.81282387e+02,  -1.49210323e+02,   5.31851869e+01,\n",
       "         -1.31877851e+01,   6.58464648e+01,   4.15359513e+01,\n",
       "         -7.59792661e+01,   3.35426610e-01,   7.28442418e+01,\n",
       "          7.11340879e+01,  -1.11221233e+01,   9.54891668e+01,\n",
       "         -7.47486724e+01,   1.97022806e+01,  -3.28645363e+01,\n",
       "         -1.34503473e+02,  -4.35110411e+01,  -1.49643621e+02,\n",
       "          2.58556434e+01,  -1.29305857e+02,   3.63571707e+01,\n",
       "          2.33050425e+01]])"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pca.fit_transform(data)\n",
    "pca.transform(curr_img.img_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.34577558e+03,   6.84556293e+02,   5.59208035e+01,\n",
       "         -8.46845980e+02,  -4.41662885e+02,  -2.76884066e+01,\n",
       "          1.44019059e+02,   3.21069032e+02,   4.93002186e+02,\n",
       "         -1.74616988e+02,  -1.44020397e+02,  -2.81885666e+02,\n",
       "         -4.09568842e+02,   1.35128162e+02,  -2.57477347e+02,\n",
       "          4.05459057e+01,   3.06752019e+02,  -2.25583296e+02,\n",
       "         -3.40521745e+01,   5.80173919e+01,  -1.31436216e+02,\n",
       "          5.92273735e+00,  -1.88621552e+01,  -4.34929528e+02,\n",
       "          9.64304280e+01,   4.16957982e+01,   1.63363781e+02,\n",
       "         -7.13771988e+01,  -2.06998188e+02,   1.45761422e+02,\n",
       "          1.26428248e+02,   7.63334545e+01,  -1.76459278e+02,\n",
       "         -1.05714390e+02,   1.10165275e+02,  -1.46324568e+02,\n",
       "          9.25733320e+01,   8.84218509e+01,  -1.71506714e+02,\n",
       "          2.86410992e+01,   8.56800328e+01,  -7.13905291e+01,\n",
       "          3.15125133e+01,   8.33700841e+01,  -9.23399038e+01,\n",
       "         -5.19382454e+01,  -1.97859510e+02,   1.43309754e+02,\n",
       "         -8.63216662e+00,   1.04687497e+02,   1.19203160e+02,\n",
       "         -2.00435826e+02,  -7.05769532e+01,   7.83407878e+01,\n",
       "         -2.48818343e+02,  -5.75694302e+01,   5.38804017e+01,\n",
       "          4.09278181e+01,   1.64915448e+02,  -2.01190270e+02,\n",
       "         -8.61174815e+01,  -1.38308200e+02,  -1.66076720e+02,\n",
       "          1.34911219e+02,  -6.67517383e+01,  -1.36253965e+01,\n",
       "         -3.74357980e+01,  -4.83355957e+01,   7.77405702e+00,\n",
       "          8.36923010e+01,  -1.00304054e+02,   1.04906262e+02,\n",
       "         -5.95667547e+01,   6.04566832e+01,  -1.68784005e+02,\n",
       "         -1.31652367e+02,   1.13253013e+02,  -9.45363635e+01,\n",
       "         -1.81282387e+02,  -1.49210323e+02,   5.31851869e+01,\n",
       "         -1.31877851e+01,   6.58464648e+01,   4.15359513e+01,\n",
       "         -7.59792661e+01,   3.35426610e-01,   7.28442418e+01,\n",
       "          7.11340879e+01,  -1.11221233e+01,   9.54891668e+01,\n",
       "         -7.47486724e+01,   1.97022806e+01,  -3.28645363e+01,\n",
       "         -1.34503473e+02,  -4.35110411e+01,  -1.49643621e+02,\n",
       "          2.58556434e+01,  -1.29305857e+02,   3.63571707e+01,\n",
       "          2.33050425e+01]])"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.transform(curr_img.img_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
